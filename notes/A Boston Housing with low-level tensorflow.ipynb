{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(dtype=tf.float32, shape=(None, 13))\n",
    "y = tf.placeholder(dtype=tf.float32, shape=(None, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dennis/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "bias = tf.Variable(tf.random_normal([1], stddev=0.05))\n",
    "weights = tf.Variable(tf.random_normal([13, 1], stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.matmul(x, weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(pred - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.train.AdamOptimizer()\n",
    "train = optimiser.minimize(loss)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.02930109], dtype=float32), array([[ 0.03431689],\n",
       "        [ 0.00040064],\n",
       "        [-0.13230708],\n",
       "        [-0.00970636],\n",
       "        [ 0.06503382],\n",
       "        [ 0.00551289],\n",
       "        [ 0.05833879],\n",
       "        [ 0.03209714],\n",
       "        [ 0.03791287],\n",
       "        [ 0.01949451],\n",
       "        [ 0.09136518],\n",
       "        [-0.07885189],\n",
       "        [ 0.00640117]], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run((bias, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1674.315"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_val, y_val) = boston_housing.load_data()\n",
    "y_train = y_train.reshape((404,1))\n",
    "sess.run(loss, {x:x_train, y:y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs   0 Loss 1674.3\n",
      "Epochs   1 Loss 1609.4\n",
      "Epochs   2 Loss 1546.3\n",
      "Epochs   3 Loss 1484.9\n",
      "Epochs   4 Loss 1425.4\n",
      "Epochs   5 Loss 1367.7\n",
      "Epochs   6 Loss 1311.8\n",
      "Epochs   7 Loss 1257.8\n",
      "Epochs   8 Loss 1205.8\n",
      "Epochs   9 Loss 1155.6\n",
      "Epochs  10 Loss 1107.3\n",
      "Epochs  11 Loss 1060.9\n",
      "Epochs  12 Loss 1016.4\n",
      "Epochs  13 Loss 973.9\n",
      "Epochs  14 Loss 933.2\n",
      "Epochs  15 Loss 894.3\n",
      "Epochs  16 Loss 857.4\n",
      "Epochs  17 Loss 822.3\n",
      "Epochs  18 Loss 788.9\n",
      "Epochs  19 Loss 757.4\n",
      "Epochs  20 Loss 727.6\n",
      "Epochs  21 Loss 699.4\n",
      "Epochs  22 Loss 673.0\n",
      "Epochs  23 Loss 648.1\n",
      "Epochs  24 Loss 624.8\n",
      "Epochs  25 Loss 603.0\n",
      "Epochs  26 Loss 582.6\n",
      "Epochs  27 Loss 563.7\n",
      "Epochs  28 Loss 546.0\n",
      "Epochs  29 Loss 529.7\n",
      "Epochs  30 Loss 514.5\n",
      "Epochs  31 Loss 500.5\n",
      "Epochs  32 Loss 487.6\n",
      "Epochs  33 Loss 475.7\n",
      "Epochs  34 Loss 464.7\n",
      "Epochs  35 Loss 454.6\n",
      "Epochs  36 Loss 445.4\n",
      "Epochs  37 Loss 436.9\n",
      "Epochs  38 Loss 429.2\n",
      "Epochs  39 Loss 422.1\n",
      "Epochs  40 Loss 415.5\n",
      "Epochs  41 Loss 409.6\n",
      "Epochs  42 Loss 404.0\n",
      "Epochs  43 Loss 399.0\n",
      "Epochs  44 Loss 394.3\n",
      "Epochs  45 Loss 390.0\n",
      "Epochs  46 Loss 385.9\n",
      "Epochs  47 Loss 382.1\n",
      "Epochs  48 Loss 378.6\n",
      "Epochs  49 Loss 375.2\n",
      "Epochs  50 Loss 372.1\n",
      "Epochs  51 Loss 369.0\n",
      "Epochs  52 Loss 366.1\n",
      "Epochs  53 Loss 363.3\n",
      "Epochs  54 Loss 360.5\n",
      "Epochs  55 Loss 357.8\n",
      "Epochs  56 Loss 355.2\n",
      "Epochs  57 Loss 352.6\n",
      "Epochs  58 Loss 350.0\n",
      "Epochs  59 Loss 347.4\n",
      "Epochs  60 Loss 344.8\n",
      "Epochs  61 Loss 342.3\n",
      "Epochs  62 Loss 339.7\n",
      "Epochs  63 Loss 337.2\n",
      "Epochs  64 Loss 334.6\n",
      "Epochs  65 Loss 332.1\n",
      "Epochs  66 Loss 329.5\n",
      "Epochs  67 Loss 326.9\n",
      "Epochs  68 Loss 324.3\n",
      "Epochs  69 Loss 321.8\n",
      "Epochs  70 Loss 319.2\n",
      "Epochs  71 Loss 316.6\n",
      "Epochs  72 Loss 314.0\n",
      "Epochs  73 Loss 311.5\n",
      "Epochs  74 Loss 308.9\n",
      "Epochs  75 Loss 306.4\n",
      "Epochs  76 Loss 303.8\n",
      "Epochs  77 Loss 301.3\n",
      "Epochs  78 Loss 298.7\n",
      "Epochs  79 Loss 296.2\n",
      "Epochs  80 Loss 293.7\n",
      "Epochs  81 Loss 291.2\n",
      "Epochs  82 Loss 288.8\n",
      "Epochs  83 Loss 286.3\n",
      "Epochs  84 Loss 283.9\n",
      "Epochs  85 Loss 281.4\n",
      "Epochs  86 Loss 279.0\n",
      "Epochs  87 Loss 276.7\n",
      "Epochs  88 Loss 274.3\n",
      "Epochs  89 Loss 271.9\n",
      "Epochs  90 Loss 269.6\n",
      "Epochs  91 Loss 267.3\n",
      "Epochs  92 Loss 265.0\n",
      "Epochs  93 Loss 262.7\n",
      "Epochs  94 Loss 260.5\n",
      "Epochs  95 Loss 258.2\n",
      "Epochs  96 Loss 256.0\n",
      "Epochs  97 Loss 253.8\n",
      "Epochs  98 Loss 251.6\n",
      "Epochs  99 Loss 249.4\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "  next_loss, _ = sess.run([loss, train], {x:x_train, y:y_train})\n",
    "  print(\"Epochs {:3d} Loss {:.1f}\".format(e, next_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
